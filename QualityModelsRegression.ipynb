{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0143193",
   "metadata": {},
   "source": [
    "Import all required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c050d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "995ef1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix_with_green_diagonal(y_true, y_pred, labels, title, figsize=(8, 6)):\n",
    "    \"\"\"\n",
    "    Plot confusion matrix with correct predictions (diagonal) highlighted in varying shades of green\n",
    "    based on the frequency of correct predictions\n",
    "    \"\"\"\n",
    "    from matplotlib.colors import ListedColormap\n",
    "    import matplotlib.colors as mcolors\n",
    "    \n",
    "    # Calculate confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "    \n",
    "    # Create a figure and axis\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    \n",
    "    # Create a normalized confusion matrix for better color scaling\n",
    "    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    \n",
    "    # Create base heatmap with purple colormap for incorrect predictions\n",
    "    im = ax.imshow(cm_normalized, interpolation='nearest', cmap='Purples', alpha=0.8)\n",
    "    \n",
    "    # Get diagonal values for green intensity scaling\n",
    "    diagonal_values = np.diag(cm)\n",
    "    max_diagonal = max(diagonal_values) if len(diagonal_values) > 0 else 1\n",
    "    min_diagonal = min(diagonal_values) if len(diagonal_values) > 0 else 0\n",
    "    \n",
    "    # Highlight diagonal (correct predictions) in varying shades of green\n",
    "    for i in range(len(labels)):\n",
    "        # Calculate green intensity based on frequency\n",
    "        frequency = diagonal_values[i]\n",
    "        if max_diagonal > min_diagonal:\n",
    "            # Normalize frequency to range 0.3-0.9 for better visibility\n",
    "            intensity = 0.3 + 0.6 * (frequency - min_diagonal) / (max_diagonal - min_diagonal)\n",
    "        else:\n",
    "            intensity = 0.6  # Default intensity if all values are the same\n",
    "        \n",
    "        # Create green color with varying intensity\n",
    "        green_color = mcolors.to_rgba('green', alpha=intensity)\n",
    "        ax.add_patch(plt.Rectangle((i-0.5, i-0.5), 1, 1, \n",
    "                                  fill=True, color=green_color))\n",
    "    \n",
    "    # Add text annotations\n",
    "    thresh = cm_normalized.max() / 2.\n",
    "    for i, j in np.ndindex(cm.shape):\n",
    "        color = 'black' if i == j else ('white' if cm_normalized[i, j] > thresh else 'black')\n",
    "        ax.text(j, i, format(cm[i, j], 'd'),\n",
    "                horizontalalignment=\"center\", \n",
    "                verticalalignment=\"center\",\n",
    "                color=color, fontweight='bold' if i == j else 'normal')\n",
    "    \n",
    "    # Set labels and title\n",
    "    ax.set_xlabel('Predicted Quality')\n",
    "    ax.set_ylabel('True Quality')\n",
    "    ax.set_title(title)\n",
    "    \n",
    "    # Set tick marks\n",
    "    ax.set_xticks(np.arange(len(labels)))\n",
    "    ax.set_yticks(np.arange(len(labels)))\n",
    "    ax.set_xticklabels(labels)\n",
    "    ax.set_yticklabels(labels)\n",
    "    \n",
    "    # Rotate the tick labels and set their alignment\n",
    "    plt.setp(ax.get_xticklabels(), rotation=0, ha=\"center\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return cm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bde2cfb",
   "metadata": {},
   "source": [
    "Lets first import the data. We will look at both red and white wine seperately."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7c5d99",
   "metadata": {},
   "source": [
    "## Data Quality Check\n",
    "Let's first examine the data to understand the quality distributions and check for any anomalies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74341401",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_wine_datasets(df_red, df_white, df_qt):\n",
    "    # Create copies of the datasets and add wine type indicators\n",
    "    df_red_copy = df_red.copy()\n",
    "    df_white_copy = df_white.copy()\n",
    "    df_qt_copy = df_qt.copy()\n",
    "\n",
    "    # Add wine type column (one-hot encoding)\n",
    "    df_red_copy['is_red_wine'] = 1\n",
    "    df_white_copy['is_red_wine'] = 0\n",
    "    df_qt_copy['is_red_wine'] = 1  # Assuming QT dataset is red wine\n",
    "\n",
    "    # Merge the datasets\n",
    "    df_merged = pd.concat([df_red_copy, df_white_copy, df_qt_copy], ignore_index=True)\n",
    "\n",
    "    print(f\"Merged dataset shape: {df_merged.shape}\")\n",
    "    print(f\"Red wine samples: {len(df_red_copy)}\")\n",
    "    print(f\"White wine samples: {len(df_white_copy)}\")\n",
    "    print(f\"QT samples: {len(df_qt_copy)}\")\n",
    "    print(f\"Total samples: {len(df_merged)}\")\n",
    "\n",
    "    return df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08176e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged dataset shape: (7640, 13)\n",
      "Red wine samples: 1599\n",
      "White wine samples: 4898\n",
      "QT samples: 1143\n",
      "Total samples: 7640\n"
     ]
    }
   ],
   "source": [
    "# Load datasets\n",
    "df_red = pd.read_csv(\"Data/Raw/Wine_Datasets/UCI_Wines/winequality-red.csv\", sep=';')\n",
    "df_white = pd.read_csv(\"Data/Raw/Wine_Datasets/UCI_Wines/winequality-white.csv\", sep=';')\n",
    "df_qt = pd.read_csv(\"Data/Raw/Wine_Datasets/Kaggle/WineQT.csv\", sep=',').drop([\"Id\"], axis=1)\n",
    "\n",
    "# Prepare datasets in a dictionary for easy looping\n",
    "datasets = {\n",
    "    'Red Wine': df_red,\n",
    "    'White Wine': df_white,\n",
    "    'Quality Test': df_qt\n",
    "}\n",
    "df_merged = merge_wine_datasets(df_red, df_white, df_qt)\n",
    "\n",
    "# Save merged dataset\n",
    "# Make directory if it doesn't exist\n",
    "import os\n",
    "os.makedirs(\"Data/Processed\", exist_ok=True)\n",
    "df_merged.to_csv(\"Data/Processed/merged_wine_quality_data.csv\", index=False)\n",
    "\n",
    "\n",
    "# Variables with high VIFs identified from previous analysis\n",
    "high_vifs = ['density', 'is_red_wine'] # Remove wine-type as it is categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bcf630c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Merged Wine Dataset ===\n",
      "Shape: (7640, 13)\n",
      "Quality column type: int64\n",
      "Quality value counts:\n",
      "quality\n",
      "3      36\n",
      "4     249\n",
      "5    2621\n",
      "6    3298\n",
      "7    1222\n",
      "8     209\n",
      "9       5\n",
      "Name: count, dtype: int64\n",
      "Quality range: 3 to 9\n",
      "Unique quality values: [np.int64(3), np.int64(4), np.int64(5), np.int64(6), np.int64(7), np.int64(8), np.int64(9)]\n",
      "Missing values in quality: 0\n",
      "Data types:\n",
      "fixed acidity           float64\n",
      "volatile acidity        float64\n",
      "citric acid             float64\n",
      "residual sugar          float64\n",
      "chlorides               float64\n",
      "free sulfur dioxide     float64\n",
      "total sulfur dioxide    float64\n",
      "density                 float64\n",
      "pH                      float64\n",
      "sulphates               float64\n",
      "alcohol                 float64\n",
      "quality                   int64\n",
      "is_red_wine               int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Check the quality distributions and data integrity\n",
    "for name, df in [(\"Merged Wine\", df_merged)]:\n",
    "    print(f\"\\n=== {name} Dataset ===\")\n",
    "    print(f\"Shape: {df.shape}\")\n",
    "    print(f\"Quality column type: {df['quality'].dtype}\")\n",
    "    print(f\"Quality value counts:\")\n",
    "    print(df['quality'].value_counts().sort_index())\n",
    "    print(f\"Quality range: {df['quality'].min()} to {df['quality'].max()}\")\n",
    "    \n",
    "    # Check for any non-integer values or outliers\n",
    "    print(f\"Unique quality values: {sorted(df['quality'].unique())}\")\n",
    "    \n",
    "    # Check for missing values\n",
    "    print(f\"Missing values in quality: {df['quality'].isnull().sum()}\")\n",
    "    \n",
    "    # Check data types of all columns\n",
    "    print(f\"Data types:\")\n",
    "    print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2be70cf",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07ac2b06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Merged Wine - Logistic Regression ===\n",
      "Target (y) range before split: 3 to 9\n",
      "Target (y) unique values: [np.int64(3), np.int64(4), np.int64(5), np.int64(6), np.int64(7), np.int64(8), np.int64(9)]\n",
      "y_train range: 3 to 9\n",
      "y_test range: 3 to 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Edwar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\sklearn\\linear_model\\_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions range: 4 to 7\n",
      "Unique predictions: [np.int64(4), np.int64(5), np.int64(6), np.int64(7)]\n",
      "Logistic Regression Accuracy (6 classes): 0.541\n",
      "Classes present in test/pred data: [np.int64(3), np.int64(4), np.int64(5), np.int64(6), np.int64(7), np.int64(8)]\n",
      "\n",
      "Per-class metrics:\n",
      "Class 3  Precision: 0.000  Recall: 0.000  F1: 0.000\n",
      "Class 4  Precision: 1.000  Recall: 0.019  F1: 0.036\n",
      "Class 5  Precision: 0.570  Recall: 0.638  F1: 0.602\n",
      "Class 6  Precision: 0.541  Recall: 0.653  F1: 0.592\n",
      "Class 7  Precision: 0.403  Recall: 0.226  F1: 0.290\n",
      "Class 8  Precision: 0.000  Recall: 0.000  F1: 0.000\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Logistic Regression for both datasets\n",
    "df = df_merged.copy().drop(columns=high_vifs)\n",
    "\n",
    "\n",
    "print(f\"\\n=== {name} - Logistic Regression ===\")\n",
    "\n",
    "# Separate features and labels\n",
    "X = df.drop([\"quality\"], axis=1)\n",
    "y = df[\"quality\"]\n",
    "\n",
    "# Debug: Check y values before splitting\n",
    "print(f\"Target (y) range before split: {y.min()} to {y.max()}\")\n",
    "print(f\"Target (y) unique values: {sorted(y.unique())}\")\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Debug: Check splits\n",
    "print(f\"y_train range: {y_train.min()} to {y_train.max()}\")\n",
    "print(f\"y_test range: {y_test.min()} to {y_test.max()}\")\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "# Logistic Regression (multinomial)\n",
    "log_model = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=2000, random_state=42)\n",
    "log_model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "# Predictions\n",
    "y_pred = log_model.predict(X_test_scaled)\n",
    "\n",
    "# Debug: Check predictions\n",
    "print(f\"Predictions range: {y_pred.min()} to {y_pred.max()}\")\n",
    "print(f\"Unique predictions: {sorted(np.unique(y_pred))}\")\n",
    "\n",
    "# Check if any predictions are outside expected range\n",
    "invalid_preds = y_pred[(y_pred < 3) | (y_pred > 8)]\n",
    "if len(invalid_preds) > 0:\n",
    "    print(f\"WARNING: Found {len(invalid_preds)} predictions outside range 3-8!\")\n",
    "    print(f\"Invalid predictions: {invalid_preds}\")\n",
    "    \n",
    "# Accuracy\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"Logistic Regression Accuracy (6 classes): {acc:.3f}\")\n",
    "\n",
    "# Get unique classes present in the data for proper labeling\n",
    "unique_classes = sorted(np.unique(np.concatenate([y_test, y_pred])))\n",
    "print(f\"Classes present in test/pred data: {unique_classes}\")\n",
    "    \n",
    "# Precision, recall and F1 score per class\n",
    "precisions = precision_score(y_test, y_pred, labels=unique_classes, average=None, zero_division=0)\n",
    "recalls = recall_score(y_test, y_pred, labels=unique_classes, average=None, zero_division=0)\n",
    "f1s = f1_score(y_test, y_pred, labels=unique_classes, average=None, zero_division=0)\n",
    "\n",
    "print(\"\\nPer-class metrics:\")\n",
    "for cls, p, r, f in zip(unique_classes, precisions, recalls, f1s):\n",
    "    print(f\"Class {cls:1d}  Precision: {p:.3f}  Recall: {r:.3f}  F1: {f:.3f}\")\n",
    "\n",
    "# Confusion matrix with custom coloring (green diagonal)\n",
    "cm = confusion_matrix(y_test, y_pred, labels=unique_classes)\n",
    "\n",
    "# Create custom colormap for highlighting correct predictions\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "# Create a figure and axis\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "# Create a normalized confusion matrix for better color scaling\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "# Create base heatmap with purple colormap for incorrect predictions\n",
    "im = ax.imshow(cm_normalized, interpolation='nearest', cmap='Purples', alpha=0.8)\n",
    "\n",
    "# Get diagonal values for green intensity scaling\n",
    "diagonal_values = np.diag(cm)\n",
    "max_diagonal = max(diagonal_values) if len(diagonal_values) > 0 else 1\n",
    "min_diagonal = min(diagonal_values) if len(diagonal_values) > 0 else 0\n",
    "\n",
    "# Highlight diagonal (correct predictions) in varying shades of green\n",
    "for i in range(len(unique_classes)):\n",
    "    # Calculate green intensity based on frequency\n",
    "    frequency = diagonal_values[i]\n",
    "    if max_diagonal > min_diagonal:\n",
    "        # Normalize frequency to range 0.3-0.9 for better visibility\n",
    "        intensity = 0.3 + 0.6 * (frequency - min_diagonal) / (max_diagonal - min_diagonal)\n",
    "    else:\n",
    "        intensity = 0.6  # Default intensity if all values are the same\n",
    "    \n",
    "    # Create green color with varying intensity\n",
    "    green_color = mcolors.to_rgba('green', alpha=intensity)\n",
    "    ax.add_patch(plt.Rectangle((i-0.5, i-0.5), 1, 1, \n",
    "                                fill=True, color=green_color))\n",
    "\n",
    "# Add text annotations\n",
    "thresh = cm_normalized.max() / 2.\n",
    "for i, j in np.ndindex(cm.shape):\n",
    "    color = 'black' if i == j else ('white' if cm_normalized[i, j] > thresh else 'black')\n",
    "    ax.text(j, i, format(cm[i, j], 'd'),\n",
    "            horizontalalignment=\"center\", \n",
    "            verticalalignment=\"center\",\n",
    "            color=color, fontweight='bold' if i == j else 'normal')\n",
    "\n",
    "# Set labels and title\n",
    "ax.set_xlabel('Predicted Quality')\n",
    "ax.set_ylabel('True Quality')\n",
    "ax.set_title(f'{name} - Confusion Matrix (Darker Green = Higher Frequency)')\n",
    "\n",
    "# Set tick marks\n",
    "ax.set_xticks(np.arange(len(unique_classes)))\n",
    "ax.set_yticks(np.arange(len(unique_classes)))\n",
    "ax.set_xticklabels(unique_classes)\n",
    "ax.set_yticklabels(unique_classes)\n",
    "\n",
    "# Rotate the tick labels and set their alignment\n",
    "plt.setp(ax.get_xticklabels(), rotation=0, ha=\"center\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf1c66a",
   "metadata": {},
   "source": [
    "K-Nearest-Neighbour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0ab48eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Red Wine ===\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['quality_category'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m=== \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m ===\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Separate features and labels\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m X = \u001b[43mdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mquality\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mquality_category\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m y = df[\u001b[33m\"\u001b[39m\u001b[33mquality_category\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Train-test split\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\pandas\\core\\frame.py:5581\u001b[39m, in \u001b[36mDataFrame.drop\u001b[39m\u001b[34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[39m\n\u001b[32m   5433\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdrop\u001b[39m(\n\u001b[32m   5434\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   5435\u001b[39m     labels: IndexLabel | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   5442\u001b[39m     errors: IgnoreRaise = \u001b[33m\"\u001b[39m\u001b[33mraise\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   5443\u001b[39m ) -> DataFrame | \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   5444\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   5445\u001b[39m \u001b[33;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[32m   5446\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   5579\u001b[39m \u001b[33;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[32m   5580\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m5581\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5582\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5583\u001b[39m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5584\u001b[39m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5585\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5586\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5587\u001b[39m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[43m=\u001b[49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5588\u001b[39m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5589\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\pandas\\core\\generic.py:4788\u001b[39m, in \u001b[36mNDFrame.drop\u001b[39m\u001b[34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[39m\n\u001b[32m   4786\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes.items():\n\u001b[32m   4787\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m4788\u001b[39m         obj = \u001b[43mobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4790\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[32m   4791\u001b[39m     \u001b[38;5;28mself\u001b[39m._update_inplace(obj)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\pandas\\core\\generic.py:4830\u001b[39m, in \u001b[36mNDFrame._drop_axis\u001b[39m\u001b[34m(self, labels, axis, level, errors, only_slice)\u001b[39m\n\u001b[32m   4828\u001b[39m         new_axis = axis.drop(labels, level=level, errors=errors)\n\u001b[32m   4829\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m4830\u001b[39m         new_axis = \u001b[43maxis\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4831\u001b[39m     indexer = axis.get_indexer(new_axis)\n\u001b[32m   4833\u001b[39m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[32m   4834\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\pandas\\core\\indexes\\base.py:7070\u001b[39m, in \u001b[36mIndex.drop\u001b[39m\u001b[34m(self, labels, errors)\u001b[39m\n\u001b[32m   7068\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mask.any():\n\u001b[32m   7069\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m errors != \u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m7070\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels[mask].tolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not found in axis\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   7071\u001b[39m     indexer = indexer[~mask]\n\u001b[32m   7072\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.delete(indexer)\n",
      "\u001b[31mKeyError\u001b[39m: \"['quality_category'] not found in axis\""
     ]
    }
   ],
   "source": [
    "# Set number of neighbors for KNN\n",
    "k = 5\n",
    "\n",
    "for name, df in datasets.items():\n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    \n",
    "    # Separate features and labels\n",
    "    X = df.drop([\"quality\", \"quality_category\"], axis=1)\n",
    "    y = df[\"quality_category\"]\n",
    "    \n",
    "    # Train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # K-Nearest Neighbors classifier\n",
    "    knn_model = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn_model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Predictions\n",
    "    y_pred = knn_model.predict(X_test_scaled)\n",
    "    \n",
    "    # Accuracy\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    print(f\"KNN Accuracy (k={k}): {acc:.3f}\")\n",
    "\n",
    "    # Precision, recall and F1 score (balance of the two)\n",
    "    labels = [\"low\", \"medium\", \"high\"]\n",
    "    precisions = precision_score(y_test, y_pred, labels=labels, average=None, zero_division=0)\n",
    "    recalls = recall_score(y_test, y_pred, labels=labels, average=None, zero_division=0)\n",
    "    f1s = f1_score(y_test, y_pred, labels=labels, average=None, zero_division=0)\n",
    "\n",
    "    for lab, p, r, f in zip(labels, precisions, recalls, f1s):\n",
    "        print(f\"{lab:6s}  Precision: {p:.3f}  Recall: {r:.3f}  F1: {f:.3f}\")\n",
    "    \n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred, labels=[\"low\", \"medium\", \"high\"])\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"low\", \"medium\", \"high\"])\n",
    "    disp.plot(cmap=\"Purples\", values_format=\"d\")\n",
    "    plt.title(f\"{name} - Confusion Matrix (Low / Medium / High)\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c50cdd",
   "metadata": {},
   "source": [
    "Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d054d170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network Accuracy (3 categories, 3 layers of 15 nodes): 0.566\n",
      "low     Precision: 0.000  Recall: 0.000  F1: 0.000\n",
      "medium  Precision: 0.000  Recall: 0.000  F1: 0.000\n",
      "high    Precision: 0.000  Recall: 0.000  F1: 0.000\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "At least one label specified must be in y_true",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 27\u001b[39m\n\u001b[32m     24\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlab\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m6s\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m  Precision: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mp\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m  Recall: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mr\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m  F1: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     26\u001b[39m \u001b[38;5;66;03m# Confusion matrix\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m cm = \u001b[43mconfusion_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlow\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmedium\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mhigh\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     28\u001b[39m disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\u001b[33m\"\u001b[39m\u001b[33mlow\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmedium\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mhigh\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     29\u001b[39m disp.plot(cmap=\u001b[33m\"\u001b[39m\u001b[33mPurples\u001b[39m\u001b[33m\"\u001b[39m, values_format=\u001b[33m\"\u001b[39m\u001b[33md\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\sklearn\\utils\\_param_validation.py:218\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    213\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    214\u001b[39m         skip_parameter_validation=(\n\u001b[32m    215\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    216\u001b[39m         )\n\u001b[32m    217\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    224\u001b[39m     msg = re.sub(\n\u001b[32m    225\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    226\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    227\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    228\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\sklearn\\metrics\\_classification.py:481\u001b[39m, in \u001b[36mconfusion_matrix\u001b[39m\u001b[34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[39m\n\u001b[32m    479\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m np.zeros((n_labels, n_labels), dtype=\u001b[38;5;28mint\u001b[39m)\n\u001b[32m    480\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(np.intersect1d(y_true, labels)) == \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m481\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mAt least one label specified must be in y_true\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    483\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    484\u001b[39m     sample_weight = np.ones(y_true.shape[\u001b[32m0\u001b[39m], dtype=np.int64)\n",
      "\u001b[31mValueError\u001b[39m: At least one label specified must be in y_true"
     ]
    }
   ],
   "source": [
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Neural network with 3 hidden layers, each with 15 nodes\n",
    "mlp_model = MLPClassifier(hidden_layer_sizes=(12, 12, 12), max_iter=2000, random_state=42)\n",
    "mlp_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = mlp_model.predict(X_test_scaled)\n",
    "\n",
    "# Accuracy\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"Neural Network Accuracy (3 categories, 3 layers of 15 nodes): {acc:.3f}\")\n",
    "\n",
    "# Precision, recall and F1 score (balance of the two)\n",
    "labels = [\"low\", \"medium\", \"high\"]\n",
    "precisions = precision_score(y_test, y_pred, labels=labels, average=None, zero_division=0)\n",
    "recalls = recall_score(y_test, y_pred, labels=labels, average=None, zero_division=0)\n",
    "f1s = f1_score(y_test, y_pred, labels=labels, average=None, zero_division=0)\n",
    "\n",
    "for lab, p, r, f in zip(labels, precisions, recalls, f1s):\n",
    "    print(f\"{lab:6s}  Precision: {p:.3f}  Recall: {r:.3f}  F1: {f:.3f}\")\n",
    "    \n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred, labels=[\"low\", \"medium\", \"high\"])\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"low\", \"medium\", \"high\"])\n",
    "disp.plot(cmap=\"Purples\", values_format=\"d\")\n",
    "plt.title(f\"{name} - Confusion Matrix (Low / Medium / High)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466a2905",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e022614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Red Wine ===\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['quality_category'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m=== \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m ===\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# Separate features and labels\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m X = \u001b[43mdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mquality\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mquality_category\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m y = df[\u001b[33m\"\u001b[39m\u001b[33mquality_category\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# Train-test split\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\pandas\\core\\frame.py:5581\u001b[39m, in \u001b[36mDataFrame.drop\u001b[39m\u001b[34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[39m\n\u001b[32m   5433\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdrop\u001b[39m(\n\u001b[32m   5434\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   5435\u001b[39m     labels: IndexLabel | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   5442\u001b[39m     errors: IgnoreRaise = \u001b[33m\"\u001b[39m\u001b[33mraise\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   5443\u001b[39m ) -> DataFrame | \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   5444\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   5445\u001b[39m \u001b[33;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[32m   5446\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   5579\u001b[39m \u001b[33;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[32m   5580\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m5581\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5582\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5583\u001b[39m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5584\u001b[39m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5585\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5586\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5587\u001b[39m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[43m=\u001b[49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5588\u001b[39m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5589\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\pandas\\core\\generic.py:4788\u001b[39m, in \u001b[36mNDFrame.drop\u001b[39m\u001b[34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[39m\n\u001b[32m   4786\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes.items():\n\u001b[32m   4787\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m4788\u001b[39m         obj = \u001b[43mobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4790\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[32m   4791\u001b[39m     \u001b[38;5;28mself\u001b[39m._update_inplace(obj)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\pandas\\core\\generic.py:4830\u001b[39m, in \u001b[36mNDFrame._drop_axis\u001b[39m\u001b[34m(self, labels, axis, level, errors, only_slice)\u001b[39m\n\u001b[32m   4828\u001b[39m         new_axis = axis.drop(labels, level=level, errors=errors)\n\u001b[32m   4829\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m4830\u001b[39m         new_axis = \u001b[43maxis\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4831\u001b[39m     indexer = axis.get_indexer(new_axis)\n\u001b[32m   4833\u001b[39m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[32m   4834\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\pandas\\core\\indexes\\base.py:7070\u001b[39m, in \u001b[36mIndex.drop\u001b[39m\u001b[34m(self, labels, errors)\u001b[39m\n\u001b[32m   7068\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mask.any():\n\u001b[32m   7069\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m errors != \u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m7070\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels[mask].tolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not found in axis\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   7071\u001b[39m     indexer = indexer[~mask]\n\u001b[32m   7072\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.delete(indexer)\n",
      "\u001b[31mKeyError\u001b[39m: \"['quality_category'] not found in axis\""
     ]
    }
   ],
   "source": [
    "# Prepare datasets in a dictionary for easy looping\n",
    "datasets = {\n",
    "    \"Red Wine\": df_red,\n",
    "    \"White Wine\": df_white\n",
    "}\n",
    "\n",
    "for name, df in datasets.items():\n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    \n",
    "    # Separate features and labels\n",
    "    X = df.drop([\"quality\", \"quality_category\"], axis=1)\n",
    "    y = df[\"quality_category\"]\n",
    "    \n",
    "    # Train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Optional: Scale features (Random Forests don't require scaling, but it doesn't hurt)\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Random Forest classifier\n",
    "    rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    rf_model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Predictions\n",
    "    y_pred = rf_model.predict(X_test_scaled)\n",
    "    \n",
    "    # Accuracy\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Random Forest Accuracy: {acc:.3f}\")\n",
    "    \n",
    "    # Precision, recall and F1 score (balance of the two)\n",
    "    labels = [\"low\", \"medium\", \"high\"]\n",
    "    precisions = precision_score(y_test, y_pred, labels=labels, average=None, zero_division=0)\n",
    "    recalls = recall_score(y_test, y_pred, labels=labels, average=None, zero_division=0)\n",
    "    f1s = f1_score(y_test, y_pred, labels=labels, average=None, zero_division=0)\n",
    "\n",
    "    for lab, p, r, f in zip(labels, precisions, recalls, f1s):\n",
    "        print(f\"{lab:6s}  Precision: {p:.3f}  Recall: {r:.3f}  F1: {f:.3f}\")\n",
    "\n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred, labels=[\"low\", \"medium\", \"high\"])\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"low\", \"medium\", \"high\"])\n",
    "    disp.plot(cmap=\"Purples\", values_format=\"d\")\n",
    "    plt.title(f\"{name} - Confusion Matrix (Low / Medium / High)\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013dccc7",
   "metadata": {},
   "source": [
    "From these different models, the most effective is the Random Forest model with an accuracy score of 0.9 for red wine and 0.885 for white wine.\n",
    "\n",
    "Hence we should use this model to predict the quality of the wine based on its features.\n",
    "\n",
    "From here, we now need to show how quality relates to price of wine. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
